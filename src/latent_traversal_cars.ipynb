{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Resize\n",
    "from utils import *\n",
    "from models.closedform.utils import load_generator\n",
    "from torchvision.utils import save_image\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet18\n",
    "import torch.nn as nn\n",
    "import matplotlib.pylab as plt\n",
    "import torchvision\n",
    "from torch_tools.visualization import to_image\n",
    "from torchvision.utils import make_grid\n",
    "import cv2\n",
    "from IPython import display\n",
    "from PIL import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 1234\n",
    "set_seed(random_seed)\n",
    "load_codes = False\n",
    "algo = 'ortho'\n",
    "root_dir= '/home/adarsh/PycharmProjects/disentagled_latent_dirs'\n",
    "result_path = os.path.join(root_dir,  'results/cars/closed_form_ours/qualitative_analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building generator for model `stylegan_car512` ...\n",
      "Finish building generator.\n",
      "Loading checkpoint from `../pretrained_models/generators/ClosedForm/stylegan_car512.pth` ...\n",
      "Finish loading checkpoint.\n"
     ]
    }
   ],
   "source": [
    "deformator_path = os.path.join(root_dir, 'pretrained_models/deformators/ClosedForm/stylegan_car512/stylegan_car512.pkl')\n",
    "layers, cf_deformator, _ = torch.load(deformator_path, map_location='cpu')\n",
    "cf_deformator = torch.FloatTensor(cf_deformator).cuda()\n",
    "\n",
    "deformator_path = os.path.join(root_dir, 'results/cars/models/50000_model.pkl')\n",
    "deformator = torch.load(deformator_path)['deformator']['ortho_mat']\n",
    "dse_deformator = deformator.T\n",
    "        \n",
    "generator = load_generator(None, model_name='stylegan_car512')\n",
    "\n",
    "if load_codes:\n",
    "    codes = torch.load(os.path.join(root_dir, 'results/cars/closed_form_ours/quantitative_analysis/z_analysis.pkl'))\n",
    "else:\n",
    "    num_samples = 1000\n",
    "    codes = torch.randn(num_samples, 512).cuda()\n",
    "    w = generator.mapping(codes)['w']\n",
    "    codes  = generator.truncation(w, trunc_psi = 0.7, trunc_layers = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving chart to /home/adarsh/PycharmProjects/disentagled_latent_dirs/results/cars/closedform_ours/qualitative_analysis/inspect_all_dirs_dse/0_4.jpg\n",
      "saving chart to /home/adarsh/PycharmProjects/disentagled_latent_dirs/results/cars/closedform_ours/qualitative_analysis/inspect_all_dirs_dse/5_9.jpg\n",
      "saving chart to /home/adarsh/PycharmProjects/disentagled_latent_dirs/results/cars/closedform_ours/qualitative_analysis/inspect_all_dirs_dse/10_14.jpg\n",
      "saving chart to /home/adarsh/PycharmProjects/disentagled_latent_dirs/results/cars/closedform_ours/qualitative_analysis/inspect_all_dirs_dse/15_19.jpg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c53c3b01bafd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;31m# z = torch.load(os.path.join(result_path,'temp','code_1.pkl'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0mout_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/adarsh/PycharmProjects/disentagled_latent_dirs/results/cars/closedform_ours/qualitative_analysis/inspect_all_dirs_dse'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m \u001b[0minspect_all_directions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdse_deformator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mzs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshifts_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/PycharmProjects/disentagled_latent_dirs/venv/lib/python3.6/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-c53c3b01bafd>\u001b[0m in \u001b[0;36minspect_all_directions\u001b[0;34m(G, deformator, out_dir, zs, num_z, shifts_r)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostring_rgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_width_height\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/disentagled_latent_dirs/venv/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mtostring_rgb\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0mto\u001b[0m \u001b[0mupdate\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mrenderer\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0many\u001b[0m \u001b[0msubsequent\u001b[0m \u001b[0mchanges\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mFigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \"\"\"\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostring_rgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtostring_argb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/disentagled_latent_dirs/venv/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mtostring_rgb\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtostring_rgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_renderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def add_border(tensor):\n",
    "    border = 3\n",
    "    for ch in range(tensor.shape[0]):\n",
    "        color = 1.0 if ch == 0 else -1\n",
    "        tensor[ch, :border, :] = color\n",
    "        tensor[ch, -border:,] = color\n",
    "        tensor[ch, :, :border] = color\n",
    "        tensor[ch, :, -border:] = color\n",
    "    return tensor\n",
    "\n",
    "@torch.no_grad()\n",
    "def interpolate(G, z, shifts_r, shifts_count, dim, deformator=None, with_central_border=False):\n",
    "    shifted_images = []\n",
    "    for shift in np.linspace(-shifts_r,shifts_r,shifts_count):\n",
    "        shifted_image = G.synthesis(z + (deformator[dim:dim + 1] * shift).unsqueeze(1).repeat(1,len(layers),1))\n",
    "        if shift == 0.0 and with_central_border:\n",
    "            shifted_image = add_border(shifted_image)\n",
    "        shifted_images.append(shifted_image)\n",
    "    shifted_images = torch.stack(shifted_images).squeeze(dim=1)\n",
    "    return shifted_images\n",
    "\n",
    "@torch.no_grad()\n",
    "def make_interpolation_chart(G, deformator=None, z=None,\n",
    "                             shifts_r=10.0, shifts_count=5,\n",
    "                             dims=None, dims_count=10, texts=None, **kwargs):\n",
    "\n",
    "\n",
    "    original_img = G.synthesis(z).cpu()\n",
    "    imgs = []\n",
    "    if dims is None:\n",
    "        dims = range(dims_count)\n",
    "    for i in dims:\n",
    "        imgs.append(interpolate(G, z, shifts_r, shifts_count, i, deformator))\n",
    "\n",
    "    rows_count = len(imgs) + 1\n",
    "    fig, axs = plt.subplots(rows_count, **kwargs)\n",
    "\n",
    "    axs[0].axis('off')\n",
    "    axs[0].imshow(to_image(original_img, True))\n",
    "    \n",
    "    \n",
    "\n",
    "    if texts is None:\n",
    "        texts = dims\n",
    "    for ax, shifts_imgs, text in zip(axs[1:], imgs, texts):\n",
    "        ax.axis('off')\n",
    "        plt.subplots_adjust(left=0.5)\n",
    "        ax.imshow(to_image(make_grid(shifts_imgs.clamp(min=-1, max=1), nrow=(2 * shifts_count + 1),scale_each=True, normalize=True, padding=1), True))\n",
    "        ax.text(-20, 21, str(text), fontsize=10)\n",
    "\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def inspect_all_directions(G, deformator, out_dir, zs=None, num_z=3, shifts_r=8.0):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    step = 5\n",
    "    max_dim = 128\n",
    "    codes = zs.cuda()\n",
    "    w = G.mapping(codes)['w']\n",
    "    zs  = G.truncation(w, trunc_psi = 0.7, trunc_layers = 8)\n",
    "    shifts_count = zs.shape[0]\n",
    "\n",
    "    for start in range(0, max_dim - 1, step):\n",
    "        imgs = []\n",
    "        dims = range(start, min(start + step, max_dim))\n",
    "        for z in zs:\n",
    "            z = z.unsqueeze(0)\n",
    "            fig = make_interpolation_chart(\n",
    "                G, deformator=deformator, z=z,\n",
    "                shifts_count=5, dims=dims, shifts_r=shifts_r,\n",
    "                dpi=250, figsize=(int(shifts_count * 4.0), int(0.5 * step) + 2))\n",
    "            fig.canvas.draw()\n",
    "            plt.close(fig)\n",
    "            img = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "            img = img.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "\n",
    "            # crop borders\n",
    "            nonzero_columns = np.count_nonzero(img != 255, axis=0)[:, 0] > 0\n",
    "            img = img.transpose(1, 0, 2)[nonzero_columns].transpose(1, 0, 2)\n",
    "            imgs.append(img)\n",
    "\n",
    "        out_file = os.path.join(out_dir, '{}_{}.jpg'.format(dims[0], dims[-1]))\n",
    "        print('saving chart to {}'.format(out_file))\n",
    "        Image.fromarray(np.hstack(imgs)).save(out_file)\n",
    "        \n",
    "# z = torch.load('codes.pkl').cuda()\n",
    "z = torch.randn(3, 512)\n",
    "# z = torch.load(os.path.join(result_path,'temp','code_1.pkl'))\n",
    "out_dir = '/home/adarsh/PycharmProjects/disentagled_latent_dirs/results/cars/closedform_ours/qualitative_analysis/inspect_all_dirs_dse'\n",
    "inspect_all_directions(generator, dse_deformator,out_dir,zs=z, shifts_r=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def postprocess_images(images):\n",
    "        \"\"\"Post-processes images from `torch.Tensor` to `numpy.ndarray`.\"\"\"\n",
    "        images = images.detach().cpu().numpy()\n",
    "        images = (images + 1) * 255 / 2\n",
    "        images = np.clip(images + 0.5, 0, 255).astype(np.uint8)\n",
    "        images = images.transpose(0, 2, 3, 1)\n",
    "        return images\n",
    "\n",
    "\n",
    "def save_images(codes, shifts_r, shifts_count, cf_dir, dse_dir, generator, cf_deformator, dse_deformator):\n",
    "        plt.figure(figsize=(30,30))\n",
    "        for idx, z in enumerate(codes):\n",
    "            print('Figure : ' + str(idx))\n",
    "            z_shift_cf = []\n",
    "            z_shift_dse = []\n",
    "            for i, shift in enumerate(np.linspace(-shifts_r,shifts_r,shifts_count)):\n",
    "                z_shift_cf.append(z + cf_deformator[cf_dir: cf_dir + 1] * shift)\n",
    "                z_shift_dse.append(z + dse_deformator[dse_dir: dse_dir + 1] * shift)\n",
    "            z_shift_cf = torch.stack(z_shift_cf).squeeze(dim=1)\n",
    "            z_shift_dse = torch.stack(z_shift_dse).squeeze(dim=1)\n",
    "            with torch.no_grad():\n",
    "                cf_images= generator(z_shift_cf)\n",
    "            torch.save(cf_images, os.path.join(result_path, 'temp', 'cf.pkl'))\n",
    "            del cf_images\n",
    "            with torch.no_grad():\n",
    "                dse_images= generator(z_shift_dse)\n",
    "            torch.save(dse_images, os.path.join(result_path, 'temp', 'dse.pkl'))\n",
    "            del dse_images\n",
    "            cf_images = torch.load(os.path.join(result_path, 'temp', 'cf.pkl'))\n",
    "            dse_images = torch.load(os.path.join(result_path, 'temp', 'dse.pkl'))\n",
    "            all_images = torch.cat((cf_images, dse_images), dim=0)\n",
    "            grid = torchvision.utils.make_grid(all_images.clamp(min=-1, max=1),nrow=10, scale_each=True, normalize=True)\n",
    "            display.display(plt.gcf())\n",
    "            plt.imshow(grid.permute(1, 2, 0).cpu().numpy())\n",
    "            del all_images\n",
    "            del cf_images\n",
    "            del dse_images\n",
    "            del grid\n",
    "\n",
    "    \n",
    "z_min_index = 0\n",
    "z_max_index = 5\n",
    "cf_dir = 1\n",
    "dse_dir = 1\n",
    "shift_r = 10\n",
    "shift_count = 10\n",
    "all_images = save_images(codes[z_min_index:z_max_index], shift_r, shift_count, cf_dir, dse_dir, generator, cf_deformator, dse_deformator)                    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
