{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Resize\n",
    "from utils import *\n",
    "from models.latentdiscovery.utils import load_generator\n",
    "from models.latentdiscovery.latent_deformator import LatentDeformator\n",
    "from torchvision.utils import save_image\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet18\n",
    "import torch.nn as nn\n",
    "import matplotlib.pylab as plt\n",
    "import torchvision\n",
    "import cv2\n",
    "from IPython import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(dims, value, indx):\n",
    "    vec = torch.zeros(dims)\n",
    "    vec[indx] = value\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 1234\n",
    "set_seed(random_seed)\n",
    "load_codes = True\n",
    "algo = 'ortho'\n",
    "root_directory= '/home/adarsh/PycharmProjects/disentagled_latent_dirs'\n",
    "result_path = os.path.join(root_directory,  'results/celeba_hq/latent_discovery_ours/qualitative_analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = load_generator(None, model_name='pggan_celebahq1024', gan_type='ProgGAN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "deformator_path = os.path.join(root_directory, 'pretrained_models/deformators/LatentDiscovery/pggan_celebahq1024/deformator_0.pt')\n",
    "directions = torch.load(deformator_path, map_location='cpu')\n",
    "root_deformator = LatentDeformator(shift_dim=generator.dim_z,\n",
    "                      input_dim=512,  # dimension of one-hot encoded vector\n",
    "                      out_dim=generator.dim_z[0],\n",
    "                      type='projection',\n",
    "                      random_init=True).cuda()\n",
    "root_deformator.load_state_dict(directions)\n",
    "root_deformator.cuda()\n",
    "\n",
    "\n",
    "deformator_path = os.path.join(root_directory, 'results/celeba_hq/latent_discovery_ours/models/22000_model.pkl')\n",
    "if algo == 'ortho':\n",
    "    dse_deformator = torch.load(deformator_path)['deformator']['ortho_mat']\n",
    "    q, r = torch.qr(dse_deformator)\n",
    "    unflip = torch.diag(r).sign().add(0.5).sign()\n",
    "    q *= unflip[..., None, :]\n",
    "    dse_deformator = q.T\n",
    "    dse_deformator.cuda()\n",
    "\n",
    "elif algo == 'linear':\n",
    "    deformator = torch.load(os.path.join(deformator_path))['deformator']\n",
    "    dse_deformator = deformator.T\n",
    "        \n",
    "\n",
    "\n",
    "# if load_codes:\n",
    "#     codes = np.load(os.path.join(root_dir, 'pretrained_models/latent_codes/pggan_celebahq1024_latents.npy'))\n",
    "#     codes = torch.from_numpy(codes).type(torch.FloatTensor).cuda()\n",
    "#     codes = torch.load(os.path.join(root_dir, 'results/celeba_hq/closed_form_ours/quantitative_analysis/z_analysis.pkl'))\n",
    "# else:\n",
    "num_samples = 1000\n",
    "codes = torch.randn(num_samples, 512, 1, 1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def postprocess_images(images):\n",
    "        \"\"\"Post-processes images from `torch.Tensor` to `numpy.ndarray`.\"\"\"\n",
    "        images = images.detach().cpu().numpy()\n",
    "        images = (images + 1) * 255 / 2\n",
    "        images = np.clip(images + 0.5, 0, 255).astype(np.uint8)\n",
    "        images = images.transpose(0, 2, 3, 1)\n",
    "        return images\n",
    "\n",
    "\n",
    "def save_images(codes, shifts_r, shifts_count, root_dir, dse_dir, generator, root_deformator, dse_deformator):\n",
    "        plt.figure(figsize=(30,30))\n",
    "        for idx, z in enumerate(codes):\n",
    "            print('Figure : ' + str(idx))\n",
    "            z_shift_root = []\n",
    "            z_shift_dse = []\n",
    "            for i, shift in enumerate(np.linspace(-shifts_r,shifts_r,shifts_count)):\n",
    "                \n",
    "                latent_shift = root_deformator(one_hot(512, shift, root_dir).cuda())\n",
    "                z_shifted = z + latent_shift\n",
    "                z_shift_root.append(z_shifted)\n",
    "                \n",
    "                latent_shift = dse_deformator[dse_dir: dse_dir + 1] * shift\n",
    "                z_shifted = z + latent_shift.view(1,512,1,1)\n",
    "                z_shift_dse.append(z_shifted)\n",
    "                \n",
    "            z_shift_root = torch.stack(z_shift_root).squeeze(dim=1)\n",
    "            z_shift_dse = torch.stack(z_shift_dse).squeeze(dim=1)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                root_images= generator(z_shift_root)\n",
    "            torch.save(root_images, os.path.join(result_path, 'temp', 'cf.pkl'))\n",
    "            del root_images\n",
    "            with torch.no_grad():\n",
    "                dse_images= generator(z_shift_dse)\n",
    "            torch.save(dse_images, os.path.join(result_path, 'temp', 'dse.pkl'))\n",
    "            del dse_images\n",
    "            root_images = torch.load(os.path.join(result_path, 'temp', 'cf.pkl'))\n",
    "            dse_images = torch.load(os.path.join(result_path, 'temp', 'dse.pkl'))\n",
    "            all_images = torch.cat((root_images, dse_images), dim=0)\n",
    "            grid = torchvision.utils.make_grid(all_images.clamp(min=-1, max=1),nrow=3, scale_each=True, normalize=True)\n",
    "            display.display(plt.gcf())\n",
    "            plt.imshow(grid.permute(1, 2, 0).cpu().numpy())\n",
    "            del all_images\n",
    "            del root_images\n",
    "            del dse_images\n",
    "            del grid\n",
    "\n",
    "    \n",
    "z_min_index = 40\n",
    "z_max_index = 50\n",
    "root_dir = 94\n",
    "dse_dir = 196\n",
    "shift_r = 10\n",
    "shift_count = 3\n",
    "all_images = save_images(codes[z_min_index:z_max_index], shift_r, shift_count, root_dir, dse_dir, generator, root_deformator, dse_deformator)                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxes = [12,196,16,137,87,119,63,118,94,167]\n",
    "selected_dirs = torch.zeros((512,len(idxes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_dirs = [directions['linear.weight'][:,idx] for idx in idxes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,idx in enumerate(idxes):\n",
    "    selected_dirs[:,i] = directions['linear.weight'][:,idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(selected_dirs,'selected_dirs.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12,196,16,137,87,119,63,118,94,167"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
