{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_image = torch.load('../results/shapes_3d/closedform/latent_traversal_eps3/result_images3.pth')\n",
    "cf_image_ours = torch.load('../results/shapes_3d/closedform_ours/latent_traversal_params_eps3/result_images3.pth')\n",
    "cf_image_sample_two = torch.load('../results/shapes_3d/closedform/latent_traversal_eps3/result_images5.pth')\n",
    "cf_image_ours_sample_two = torch.load('../results/shapes_3d/closedform_ours/latent_traversal_params_eps3/result_images5.pth')\n",
    "\n",
    "cf_image_wall = torch.load('../results/shapes_3d/closedform/latent_traversal_eps3/result_images43.pth')\n",
    "cf_image_ours_wall = torch.load('../results/shapes_3d/closedform_ours/latent_traversal_params_eps3/result_images43.pth')\n",
    "cf_image_sample_two_wall = torch.load('../results/shapes_3d/closedform/latent_traversal_eps3/result_images72.pth')\n",
    "cf_image_ours_sample_two_wall = torch.load('../results/shapes_3d/closedform_ours/latent_traversal_params_eps3/result_images72.pth')\n",
    "\n",
    "cf_image_object = torch.load('../results/shapes_3d/closedform/latent_traversal_eps3/result_images68.pth')\n",
    "cf_image_ours_object = torch.load('../results/shapes_3d/closedform_ours/latent_traversal_params_eps3/result_images68.pth')\n",
    "cf_image_sample_two_object = torch.load('../results/shapes_3d/closedform/latent_traversal_eps3/result_images7.pth')\n",
    "cf_image_ours_sample_two_object = torch.load('../results/shapes_3d/closedform_ours/latent_traversal_params_eps3/result_images7.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = torch.stack([cf_image[30:40],\n",
    "                          torch.flipud(cf_image_ours[30:40]),\n",
    "                          cf_image_sample_two[30:40],\n",
    "                          torch.flipud(cf_image_ours_sample_two[30:40]),\n",
    "                          cf_image_wall[40:50],\n",
    "                          cf_image_ours_wall[40:50],\n",
    "                          cf_image_sample_two_wall[40:50],\n",
    "                          cf_image_ours_sample_two_wall[40:50],\n",
    "                          cf_image_object[50:60],\n",
    "                          cf_image_ours_object[50:60],\n",
    "                          cf_image_sample_two_object[50:60],\n",
    "                          cf_image_ours_sample_two_object[50:60]\n",
    "                         ]).view(-1,20,3,64,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_list = ['Floor hue                               ',\n",
    "             'Wall hue                               ',\n",
    "             'Object hue                               ','Floor hue','Object hue','Object hue']\n",
    "algo = ['SeFa', 'SeFa + SRE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "SMALL_SIZE = 8\n",
    "plt.rc('axes', titlesize=22, labelsize=20)\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "plt.rcParams[\"figure.facecolor\"] = 'w'\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "fig = plt.figure(figsize=(30, 10))\n",
    "gs = gridspec.GridSpec(6, 1, wspace=0.01, hspace=0.01)\n",
    "ax = np.zeros(6, dtype=object)\n",
    "count = 0\n",
    "for i in range(6):\n",
    "    for j in range(1):\n",
    "        ax[count] = fig.add_subplot(gs[i, j])\n",
    "        grid = torchvision.utils.make_grid(all_images[i],nrow=10, scale_each=True, normalize=True)\n",
    "        ax[count].imshow(grid.permute(1, 2, 0).cpu().numpy())\n",
    "        ax[count].grid(False)\n",
    "        ax[count].set_xticks([])\n",
    "        ax[count].set_yticks([])\n",
    "        count = count + 1\n",
    "#         ax[i].title.set_text(attr_list[i])\n",
    "# ax[0].set_ylabel(attr_list[0], rotation=90,fontsize=30)\n",
    "# ax[1].set_ylabel(attr_list[1], rotation=90,fontsize=30)\n",
    "# ax[2].set_ylabel(attr_list[2], rotation=90,fontsize=30)\n",
    "\n",
    "\n",
    "gs.tight_layout(fig)\n",
    "plt.savefig('latent_traversal_shapes3d_appendix_1.pdf', bbox_inches = 'tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
