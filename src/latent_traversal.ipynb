{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Resize\n",
    "from utils import *\n",
    "from models.closedform.utils import load_generator\n",
    "from torchvision.utils import save_image\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet18\n",
    "import torch.nn as nn\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 1234\n",
    "set_seed(random_seed)\n",
    "load_codes = True\n",
    "root_folder = '/home/adarsh/PycharmProjects/disentagled_latent_dirs'\n",
    "result_path = os.path.join(root_folder, 'results/celeba_hq/closed_form/quantitative_analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building generator for model `pggan_celebahq1024` ...\n",
      "Finish building generator.\n",
      "Loading checkpoint from `../pretrained_models/generators/ClosedForm/pggan_celebahq1024.pth` ...\n",
      "Finish loading checkpoint.\n"
     ]
    }
   ],
   "source": [
    "deformator_path = os.path.join(root_folder, 'results/celeba_hq/closed_form_ours/models/18000_model.pkl')\n",
    "deformator_path = os.path.join(root_folder, 'pretrained_models/deformators/ClosedForm/pggan_celebahq1024/pggan_celebahq1024.pkl')\n",
    "_, root_deformator, _ = torch.load(deformator_path, map_location='cpu')\n",
    "root_deformator = torch.FloatTensor(root_deformator).cuda()\n",
    "\n",
    "algo == 'ortho'\n",
    "if algo == 'ortho':\n",
    "    deformator = torch.load(deformator_path)['deformator']['ortho_mat']\n",
    "    dse_deformator = deformator.T\n",
    "elif algo == 'linear':\n",
    "    deformator = torch.load(os.path.join(deformator_path))['deformator']\n",
    "    dse_deformator = deformator.T\n",
    "        \n",
    "generator = load_generator(None, model_name='pggan_celebahq1024')\n",
    "\n",
    "if load_codes:\n",
    "    codes = np.load(os.path.join(root_folder, 'pretrained_models/latent_codes/pggan_celebahq1024_latents.npy'))\n",
    "    codes = torch.from_numpy(codes).type(torch.FloatTensor).cuda()\n",
    "else:\n",
    "    num_samples = 10\n",
    "    codes = torch.randn(num_samples, generator.z_space_dim).cuda()\n",
    "    codes = generator.layer0.pixel_norm(codes)\n",
    "    codes = codes.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(self, z, shifts_r, shifts_count, dir, generator, deformator, path):\n",
    "    for i, shift in enumerate(np.linspace(-shifts_r,shifts_r,shifts_count )):\n",
    "        w_shift = z + deformator[dir: dir + 1] * shift\n",
    "        images_shifted = generator(w_shift)\n",
    "        # images_shifted = (images_shifted + 1) / 2\n",
    "        images_shifted = self._postprocess_images(images_shifted)\n",
    "        images_shifted = images_shifted.reshape(1024, 1024, 3)\n",
    "        cv2.imwrite(os.path.join(path, 'image_' + str(i) + '.jpg'), images_shifted[:, :, ::-1])\n",
    "\n",
    "        \n",
    "def postprocess(images):\n",
    "        \"\"\"Post-processes images from `torch.Tensor` to `numpy.ndarray`.\"\"\"\n",
    "        images = images.detach().cpu().numpy()\n",
    "        images = (images + 1) * 255 / 2\n",
    "        images = np.clip(images + 0.5, 0, 255).astype(np.uint8)\n",
    "        images = images.transpose(0, 2, 3, 1)\n",
    "        return images\n",
    "    \n",
    "direction = 1\n",
    "shift_r = 10\n",
    "shift_count = 11\n",
    "\n",
    "save_images(codes, shift_r, shift_count, direction, generator, root_deformator, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "num_images = 10\n",
    "all_images = torch.FloatTensor().cuda()\n",
    "for i in range(num_images):\n",
    "    images = torch.load(visualisation_data_path + '/images/images_new_direction_'+str(direction) + '/image_'+str(i)+'.pkl')\n",
    "    image = torch.cat((images[0], images[1])).detach()\n",
    "    all_images = torch.cat((all_images, image))\n",
    "    del image, images\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "plt.figure(figsize= (60,60))\n",
    "grid = torchvision.utils.make_grid(all_images.clamp(min=-1, max=1),nrow=2, scale_each=True, normalize=True)\n",
    "plt.imshow(grid.permute(1, 2, 0).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54726729\n"
     ]
    }
   ],
   "source": [
    "# z = codes[2].view(-1,512)\n",
    "# direction = 70\n",
    "# cf_image_path = 'images_cf/'\n",
    "# ours_image_path = 'images_ours/'\n",
    "# save_images(z, shifts_r, shifts_count, direction, G, deformator_cf, cf_image_path)\n",
    "# save_images(z, shifts_r, shifts_count, direction, G, deformator_ours, ours_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "images = []\n",
    "for img_path in glob.glob('images/*.png'):\n",
    "    images.append(mpimg.imread(img_path))\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "columns = 10\n",
    "for i, image in enumerate(images):\n",
    "    plt.subplot(len(images) / columns + 1, columns, i + 1)\n",
    "    plt.imshow(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
