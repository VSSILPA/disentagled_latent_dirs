{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Resize\n",
    "from utils import *\n",
    "from models.latentdiscovery.utils import load_generator\n",
    "from torchvision.utils import save_image\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet18\n",
    "import torch.nn as nn\n",
    "import matplotlib.pylab as plt\n",
    "from ortho_utils import torch_expm\n",
    "from torchvision.transforms import Resize\n",
    "from torchvision.utils import make_grid\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import io\n",
    "import os\n",
    "\n",
    "from torch_tools.visualization import to_image\n",
    "import torchvision\n",
    "import cv2\n",
    "from IPython import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 219\n",
    "set_seed(random_seed)\n",
    "# load_codes = True\n",
    "algo = 'ortho'\n",
    "root_dir= '/home/adarsh/PycharmProjects/disentagled_latent_dirs'\n",
    "result_path = os.path.join(root_dir,  'results/anime/latent_discovery_ours/qualitative_analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deformator_path = os.path.join(root_dir, 'pretrained_models/deformators/LatentDiscovery/sngan_animefaces/deformator_0.pt')\n",
    "root_deformator = torch.load(deformator_path, map_location='cpu')\n",
    "root_deformator = torch.FloatTensor(root_deformator['log_mat_half']).cuda()\n",
    "root_deformator = torch_expm((root_deformator - root_deformator.transpose(0, 1)).unsqueeze(0)).T\n",
    "\n",
    "deformator_path = os.path.join(root_dir, '/home/adarsh/PycharmProjects/disentagled_latent_dirs/results/anime/latent_discovery_ours/models/20000_model.pkl')\n",
    "if algo == 'ortho':\n",
    "    deformator = torch.load(deformator_path)['deformator']['ortho_mat']\n",
    "    dse_deformator = deformator\n",
    "    \n",
    "q, r = torch.qr(dse_deformator.data)\n",
    "unflip = torch.diag(r).sign().add(0.5).sign()\n",
    "q *= unflip[..., None, :]\n",
    "dse_deformator.data = q\n",
    "dse_deformator = dse_deformator.T\n",
    "        \n",
    "generator = load_generator(None, model_name='sngan_animefaces',gan_type='SNGAN')\n",
    "\n",
    "num_samples = 1000\n",
    "codes = torch.randn(num_samples, generator.dim_z).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# def add_border(tensor):\n",
    "#     border = 3\n",
    "#     for ch in range(tensor.shape[0]):\n",
    "#         color = 1.0 if ch == 0 else -1\n",
    "#         tensor[ch, :border, :] = color\n",
    "#         tensor[ch, -border:,] = color\n",
    "#         tensor[ch, :, :border] = color\n",
    "#         tensor[ch, :, -border:] = color\n",
    "#     return tensor\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def interpolate(G, z, shifts_r, shifts_count, dim, deformator=None, with_central_border=False):\n",
    "#     shifted_images = []\n",
    "#     for shift in np.linspace(-shifts_r,shifts_r,shifts_count):\n",
    "#         shifted_image = G(z + deformator[dim: dim + 1] * shift).cpu()[0]\n",
    "#         if shift == 0.0 and with_central_border:\n",
    "#             shifted_image = add_border(shifted_image)\n",
    "#         shifted_images.append(shifted_image)\n",
    "#     return shifted_images\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def make_interpolation_chart(G, deformator=None, z=None,\n",
    "#                              shifts_r=10.0, shifts_count=5,\n",
    "#                              dims=None, dims_count=10, texts=None, **kwargs):\n",
    "\n",
    "\n",
    "#     original_img = G(z).cpu()\n",
    "#     imgs = []\n",
    "#     if dims is None:\n",
    "#         dims = range(dims_count)\n",
    "#     for i in dims:\n",
    "#         imgs.append(interpolate(G, z, shifts_r, shifts_count, i, deformator))\n",
    "\n",
    "#     rows_count = len(imgs) + 1\n",
    "#     fig, axs = plt.subplots(rows_count, **kwargs)\n",
    "\n",
    "#     axs[0].axis('off')\n",
    "#     axs[0].imshow(to_image(original_img, True))\n",
    "\n",
    "#     if texts is None:\n",
    "#         texts = dims\n",
    "#     for ax, shifts_imgs, text in zip(axs[1:], imgs, texts):\n",
    "#         ax.axis('off')\n",
    "#         plt.subplots_adjust(left=0.5)\n",
    "#         ax.imshow(to_image(make_grid(shifts_imgs, nrow=(2 * shifts_count + 1), padding=1), True))\n",
    "#         ax.text(-20, 21, str(text), fontsize=10)\n",
    "\n",
    "\n",
    "#     return fig\n",
    "\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def inspect_all_directions(G, deformator, out_dir, zs=None, num_z=3, shifts_r=8.0):\n",
    "#     os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "#     step = 5\n",
    "#     max_dim = G.dim_shift\n",
    "#     zs = zs if zs is not None else make_noise(num_z, G.dim_z).cuda()\n",
    "#     shifts_count = zs.shape[0]\n",
    "\n",
    "#     for start in range(0, max_dim - 1, step):\n",
    "#         imgs = []\n",
    "#         dims = range(start, min(start + step, max_dim))\n",
    "#         for z in zs:\n",
    "#             z = z.unsqueeze(0)\n",
    "#             fig = make_interpolation_chart(\n",
    "#                 G, deformator=deformator, z=z,\n",
    "#                 shifts_count=5, dims=dims, shifts_r=shifts_r,\n",
    "#                 dpi=250, figsize=(int(shifts_count * 4.0), int(0.5 * step) + 2))\n",
    "#             fig.canvas.draw()\n",
    "#             plt.close(fig)\n",
    "#             img = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "#             img = img.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "\n",
    "#             # crop borders\n",
    "#             nonzero_columns = np.count_nonzero(img != 255, axis=0)[:, 0] > 0\n",
    "#             img = img.transpose(1, 0, 2)[nonzero_columns].transpose(1, 0, 2)\n",
    "#             imgs.append(img)\n",
    "\n",
    "#         out_file = os.path.join(out_dir, '{}_{}.jpg'.format(dims[0], dims[-1]))\n",
    "#         print('saving chart to {}'.format(out_file))\n",
    "#         Image.fromarray(np.hstack(imgs)).save(out_file)\n",
    "        \n",
    "# z = torch.load('codes.pkl').cuda()\n",
    "# out_dir = '/home/adarsh/PycharmProjects/disentagled_latent_dirs/results/anime/latent_discovery_ours/inspect_all_dirs'\n",
    "# inspect_all_directions(generator, dse_deformator,out_dir,zs=z, shifts_r=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def postprocess_images(images):\n",
    "        \"\"\"Post-processes images from `torch.Tensor` to `numpy.ndarray`.\"\"\"\n",
    "        images = images.detach().cpu().numpy()\n",
    "        images = (images + 1) * 255 / 2\n",
    "        images = np.clip(images + 0.5, 0, 255).astype(np.uint8)\n",
    "        images = images.transpose(0, 2, 3, 1)\n",
    "        return images\n",
    "\n",
    "\n",
    "def save_images(codes, shifts_r, shifts_count, root_dir, dse_dir, generator, root_deformator, dse_deformator):\n",
    "        temp_path = os.path.join(result_path, 'temp_' + str(root_dir) + '_' + str(dse_dir))\n",
    "        os.makedirs(temp_path, exist_ok=True)\n",
    "#         torch.save(codes, os.path.join(temp_path, 'codes.pkl'))\n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        for idx, z in enumerate(codes):\n",
    "            print('Figure : ' + str(idx))\n",
    "            z_shift_root = []\n",
    "            z_shift_dse = []\n",
    "            for i, shift in enumerate(np.linspace(-shifts_r,shifts_r,shifts_count)):\n",
    "                z_shift_root.append(z + root_deformator[root_dir: root_dir + 1] * shift)\n",
    "                z_shift_dse.append(z + dse_deformator[dse_dir: dse_dir + 1] * shift)\n",
    "            z_shift_root = torch.stack(z_shift_root).squeeze(dim=1)\n",
    "            z_shift_dse = torch.stack(z_shift_dse).squeeze(dim=1)\n",
    "            with torch.no_grad():\n",
    "                root_images= generator(z_shift_root)\n",
    "            torch.save(root_images, os.path.join(temp_path, 'cf.pkl'))\n",
    "            del root_images\n",
    "            with torch.no_grad():\n",
    "                dse_images= generator(z_shift_dse)\n",
    "            torch.save(dse_images, os.path.join(temp_path, 'dse.pkl'))\n",
    "            del dse_images\n",
    "            root_images = torch.load(os.path.join(temp_path, 'cf.pkl'))\n",
    "            dse_images = torch.load(os.path.join(temp_path, 'dse.pkl'))\n",
    "            all_images = torch.cat((root_images, dse_images), dim=0)\n",
    "            grid = torchvision.utils.make_grid(all_images.clamp(min=-1, max=1),nrow=3, scale_each=True, normalize=True)\n",
    "            display.display(plt.gcf())\n",
    "            plt.imshow(grid.permute(1, 2, 0).cpu().numpy())\n",
    "#             plt.imsave(os.path.join(temp_path, str(indices[idx])) + '.png', grid.permute(1, 2, 0).cpu().numpy(),dpi=300)\n",
    "#             im = Image.open(os.path.join(temp_path, str(indices[idx])) + '.png')\n",
    "#             im = im.resize((300, 300), Image.ANTIALIAS)\n",
    "#             im.save(os.path.join(temp_path, str(indices[idx])) + '.png',dpi=[300,300])\n",
    "#             del all_images\n",
    "            del root_images\n",
    "            del dse_images\n",
    "            del grid\n",
    "\n",
    "z_min_index = 0\n",
    "z_max_index = 1000\n",
    "codes = codes[z_min_index:z_max_index] \n",
    "indices = list(range(z_min_index, z_max_index))\n",
    "codes = torch.load(os.path.join(result_path, 'temp_Gender', 'attr_codes.pkl'))\n",
    "# indices = [0, 3, 14, 15, 18, 23, 28, 29, 30]\n",
    "# codes = codes[indices]\n",
    "root_dir = 33\n",
    "dse_dir = 49\n",
    "shift_r = 6\n",
    "shift_count = 3\n",
    "# result_path = '/media/adarsh/DATA/Anime_temp_results'\n",
    "all_images = save_images(codes, shift_r, shift_count, root_dir, dse_dir, generator, root_deformator, dse_deformator)                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_manipulated_images(z_, shift_r, shift_count, root_dir, dse_dir, generator, root_deformator, dse_deformator):\n",
    "    z_shift_root = []\n",
    "    z_shift_dse = []\n",
    "    for i, shift in enumerate(np.linspace(-shifts_r,shifts_r,shifts_count)):\n",
    "        z_shift_root.append(z_ + root_deformator[root_dir: root_dir + 1] * shift)\n",
    "        z_shift_dse.append(z_ + dse_deformator[dse_dir: dse_dir + 1] * shift)\n",
    "    z_shift_root = torch.stack(z_shift_root).squeeze(dim=1)\n",
    "    z_shift_dse = torch.stack(z_shift_dse).squeeze(dim=1)\n",
    "    with torch.no_grad():\n",
    "        root_images= generator(z_shift_root)\n",
    "    with torch.no_grad():\n",
    "        dse_images= generator(z_shift_dse)\n",
    "    return root_images, dse_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir_= '/home/adarsh/PycharmProjects/disentagled_latent_dirs'\n",
    "result_path = os.path.join(root_dir_,  'results/anime/latent_discovery_ours/qualitative_analysis')\n",
    "attr_list = ['Age', 'Gender', 'Haircolor']\n",
    "z = []\n",
    "for each_attr in attr_list:\n",
    "    z.append(torch.load(os.path.join(result_path,  each_attr + '/attr_codes.pkl')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shifts_r = 6\n",
    "shifts_count = 3\n",
    "root_dir = 4\n",
    "dse_dir = 115\n",
    "desired_idx  = 4\n",
    "\n",
    "\n",
    "ld_age, dse_age = get_manipulated_images(z[0][desired_idx], shifts_r, shifts_count, root_dir, dse_dir, generator, root_deformator, dse_deformator)\n",
    "\n",
    "\n",
    "shifts_r = 6\n",
    "shifts_count = 3\n",
    "root_dir = 33\n",
    "dse_dir = 49\n",
    "desired_idx  = 7\n",
    "\n",
    "ld_gender, dse_gender = get_manipulated_images(z[1][desired_idx], shifts_r, shifts_count, root_dir, dse_dir, generator, root_deformator, dse_deformator)\n",
    "\n",
    "\n",
    "shifts_r = 6\n",
    "shifts_count = 3\n",
    "root_dir = 87\n",
    "dse_dir = 93\n",
    "desired_idx  = 5\n",
    "\n",
    "ld_hair, dse_hair = get_manipulated_images(z[2][desired_idx], shifts_r, shifts_count, root_dir, dse_dir, generator, root_deformator, dse_deformator)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld = torch.stack((ld_age, ld_gender, ld_hair),dim=0)\n",
    "dse = torch.stack((dse_age, dse_gender, dse_hair),dim=0)\n",
    "all_images = [ld, dse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = ['LD', 'LD + SRE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "attr_list = ['Age', 'Gender', 'Hair color']\n",
    "\n",
    "SMALL_SIZE = 8\n",
    "plt.rc('axes', titlesize=22, labelsize=20)\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "plt.rcParams[\"figure.facecolor\"] = 'w'\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20, 5))\n",
    "gs = gridspec.GridSpec(2, 3, wspace=0.1, hspace=0.01)\n",
    "ax = np.zeros(6, dtype=object)\n",
    "count = 0\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        ax[count] = fig.add_subplot(gs[i, j])\n",
    "        grid = torchvision.utils.make_grid(all_images[i][j].clamp(min=-1, max=1),nrow=3, padding=0, scale_each=True, normalize=True)\n",
    "        ax[count].imshow(grid.permute(1, 2, 0).cpu().numpy())\n",
    "        ax[count].grid(False)\n",
    "        ax[count].set_xticks([])\n",
    "        ax[count].set_yticks([])\n",
    "        ax[count].spines[\"top\"].set_visible(False)\n",
    "        ax[count].spines[\"right\"].set_visible(False)\n",
    "        ax[count].spines[\"left\"].set_visible(False)\n",
    "        ax[count].spines[\"bottom\"].set_visible(False)\n",
    "        count = count + 1\n",
    "        ax[j].title.set_text(attr_list[j])\n",
    "ax[0].set_ylabel(algo[0], rotation=90)\n",
    "ax[3].set_ylabel(algo[1], rotation=90)\n",
    "\n",
    "\n",
    "gs.tight_layout(fig)\n",
    "plt.savefig('test.pdf', bbox_inches = 'tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir_= '/home/adarsh/PycharmProjects/disentagled_latent_dirs'\n",
    "result_path = os.path.join(root_dir_,  'results/anime/latent_discovery_ours/qualitative_analysis')\n",
    "# attr_list = ['Age', 'Gender', 'Haircolor']\n",
    "attr_list = ['Haircolor']\n",
    "z = []\n",
    "for each_attr in attr_list:\n",
    "    z.append(torch.load(os.path.join(result_path,  each_attr + '/attr_codes.pkl')))\n",
    "algo = ['LD', 'LD + SRE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "SMALL_SIZE = 8\n",
    "plt.rc('axes', titlesize=22, labelsize=20)\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "plt.rcParams[\"figure.facecolor\"] = 'w'\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "\n",
    "shifts_r = 10\n",
    "shifts_count = 5\n",
    "root_dir = 87\n",
    "dse_dir = 93\n",
    "desired_idx  = [3,6,7]\n",
    "attr = 0\n",
    "\n",
    "desired_z = z[attr][desired_idx]\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "gs = gridspec.GridSpec(len(desired_z), 1, wspace=0.1, hspace=0.01)\n",
    "ax = np.zeros(len(z[attr]), dtype=object)\n",
    "count = 0\n",
    "for i in range(len(desired_z)):\n",
    "    for j in range(1):\n",
    "        ax[count] = fig.add_subplot(gs[i, j])\n",
    "        root_images, dse_images = get_manipulated_images(desired_z[i], shifts_r, shifts_count, root_dir, dse_dir, generator, root_deformator, dse_deformator)\n",
    "        all_images = torch.cat((root_images, dse_images), dim=0)\n",
    "        grid = torchvision.utils.make_grid(all_images.clamp(min=-1, max=1),nrow=5, scale_each=True, normalize=True)\n",
    "        ax[count].imshow(grid.permute(1, 2, 0).cpu().numpy())\n",
    "        ax[count].grid(False)\n",
    "        ax[count].set_xticks([])\n",
    "        ax[count].set_yticks([])\n",
    "        count = count + 1\n",
    "        del all_images\n",
    "        del root_images\n",
    "        del dse_images\n",
    "        del grid\n",
    "plt.savefig(result_path + '/appendix_images/' + attr_list[0] + '.pdf', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(codes, os.path.join(result_path, 'temp_33_49/codes.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
